"""
Step 3: Gesture Recognition Control Module
==========================================

M√¥-ƒëun ƒëi·ªÅu khi·ªÉn ESP32 th√¥ng qua nh·∫≠n di·ªán c·ª≠ ch·ªâ tay ƒë√£ ƒë∆∞·ª£c training.
Load model ƒë√£ hu·∫•n luy·ªán v√† th·ª±c hi·ªán nh·∫≠n di·ªán real-time ƒë·ªÉ ƒëi·ªÅu khi·ªÉn thi·∫øt b·ªã.

Author: ESP32 Gesture Recognition Project
"""

import os
import torch
import torch.nn as nn
import cv2
import mediapipe as mp
import yaml
import requests
import time
import numpy as np
from typing import Dict, List, Tuple, Optional
from datetime import datetime


class HandGestureModel(nn.Module):
    """Neural Network cho hand gesture recognition - copy t·ª´ Step 2"""
    
    def __init__(self, input_size=63, num_classes=5, hidden_sizes=[128, 64, 32]):
        super(HandGestureModel, self).__init__()
        
        layers = []
        prev_size = input_size
        
        for hidden_size in hidden_sizes:
            layers.extend([
                nn.Linear(prev_size, hidden_size),
                nn.ReLU(),
                nn.Dropout(0.2)
            ])
            prev_size = hidden_size
        
        layers.append(nn.Linear(prev_size, num_classes))
        
        self.network = nn.Sequential(*layers)
    
    def forward(self, x):
        return self.network(x)
    
    def predict_with_known_class(self, x):
        with torch.no_grad():
            outputs = self.forward(x)
            return torch.argmax(outputs, dim=1)


class HandLandmarksDetector:
    """L·ªõp ph√°t hi·ªán v√† tr√≠ch xu·∫•t landmark t·ª´ b√†n tay"""
    
    def __init__(self, detection_confidence=0.7, tracking_confidence=0.5):
        self.mp_hands = mp.solutions.hands
        self.hands = self.mp_hands.Hands(
            static_image_mode=False,
            max_num_hands=1,
            min_detection_confidence=detection_confidence,
            min_tracking_confidence=tracking_confidence
        )
        self.mp_draw = mp.solutions.drawing_utils
    
    def extract_landmarks(self, frame):
        """Tr√≠ch xu·∫•t landmarks t·ª´ frame"""
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = self.hands.process(rgb_frame)
        
        if results.multi_hand_landmarks:
            landmarks = []
            hand_landmarks = results.multi_hand_landmarks[0]  # Ch·ªâ l·∫•y b√†n tay ƒë·∫ßu ti√™n
            
            for landmark in hand_landmarks.landmark:
                landmarks.extend([landmark.x, landmark.y, landmark.z])
            
            return landmarks, hand_landmarks
        
        return None, None
    
    def draw_landmarks(self, frame, hand_landmarks):
        """V·∫Ω landmarks l√™n frame"""
        if hand_landmarks:
            self.mp_draw.draw_landmarks(
                frame, hand_landmarks, self.mp_hands.HAND_CONNECTIONS
            )


class ESP32Controller:
    """L·ªõp ƒëi·ªÅu khi·ªÉn ESP32 th√¥ng qua HTTP requests"""
    
    def __init__(self, esp32_ip: str = "192.168.1.100", port: int = 80):
        self.esp32_ip = esp32_ip
        self.port = port
        self.base_url = f"http://{esp32_ip}:{port}"
        self.toggle_url = f"{self.base_url}/toggle/"
        
        # Test k·∫øt n·ªëi
        self.is_connected = self._test_connection()
        
    def _test_connection(self) -> bool:
        """Test k·∫øt n·ªëi ƒë·∫øn ESP32"""
        try:
            response = requests.get(self.base_url, timeout=3)
            if response.status_code == 200:
                print(f"‚úÖ K·∫øt n·ªëi ESP32 th√†nh c√¥ng: {self.base_url}")
                return True
            else:
                print(f"‚ö†Ô∏è ESP32 ph·∫£n h·ªìi v·ªõi status code: {response.status_code}")
                return False
        except requests.ConnectionError:
            print(f"‚ùå Kh√¥ng th·ªÉ k·∫øt n·ªëi ƒë·∫øn ESP32: {self.base_url}")
            print("üí° Ki·ªÉm tra:")
            print("   - ESP32 ƒë√£ b·∫≠t v√† k·∫øt n·ªëi WiFi")
            print("   - IP address ƒë√∫ng")
            print("   - C√πng m·∫°ng v·ªõi m√°y t√≠nh")
            return False
        except requests.Timeout:
            print(f"‚è∞ Timeout k·∫øt n·ªëi ESP32: {self.base_url}")
            return False
        except Exception as e:
            print(f"‚ùå L·ªói k·∫øt n·ªëi ESP32: {e}")
            return False
    
    def send_command(self, gesture_id: int, gesture_name: str) -> bool:
        """
        G·ª≠i l·ªánh ƒëi·ªÅu khi·ªÉn t·ªõi ESP32 d·ª±a tr√™n gesture_id
        
        Args:
            gesture_id: ID c·ªßa c·ª≠ ch·ªâ (0, 1, 2, 3, 4...)
            gesture_name: T√™n c·ª≠ ch·ªâ (ƒë·ªÉ log)
            
        Returns:
            bool: True n·∫øu g·ª≠i th√†nh c√¥ng
        """
        if not self.is_connected:
            return False
            
        try:
            # √Ånh x·∫° gesture t·ªõi LED control
            command_map = {
                0: None,        # turn_off - kh√¥ng l√†m g√¨
                1: "1",         # light1_on - toggle LED 1
                2: "1",         # light1_off - toggle LED 1
                3: "2",         # light2_on - toggle LED 2
                4: "2",         # light2_off - toggle LED 2
                5: "1",         # peace - toggle LED 1
                6: "2",         # ok - toggle LED 2
            }
            
            command = command_map.get(gesture_id)
            
            if command is None:
                return True  # turn_off command - kh√¥ng c·∫ßn g·ª≠i HTTP
            
            url = f"{self.toggle_url}{command}"
            response = requests.get(url, timeout=2)
            
            if response.status_code == 200:
                print(f"üéØ ƒê√£ g·ª≠i l·ªánh '{gesture_name}' -> LED {command}")
                return True
            else:
                print(f"‚ö†Ô∏è L·ªói g·ª≠i l·ªánh: {response.status_code}")
                return False
                
        except requests.RequestException as e:
            print(f"‚ùå L·ªói k·∫øt n·ªëi ESP32: {e}")
            return False
    
    def reconnect(self) -> bool:
        """Th·ª≠ k·∫øt n·ªëi l·∫°i ESP32"""
        print("üîÑ ƒêang th·ª≠ k·∫øt n·ªëi l·∫°i ESP32...")
        self.is_connected = self._test_connection()
        return self.is_connected


class GestureController:
    """L·ªõp ch√≠nh ƒëi·ªÅu khi·ªÉn nh·∫≠n di·ªán c·ª≠ ch·ªâ v√† g·ª≠i l·ªánh ƒë·∫øn ESP32"""
    
    def __init__(self, model_path: str, esp32_ip: str = "192.168.1.100", 
                 config_path: str = "../config.yaml"):
        
        self.model_path = model_path
        self.config_path = config_path
        
        # Load c·∫•u h√¨nh
        self.gesture_labels = self._load_gesture_config()
        self.num_classes = len(self.gesture_labels)
        
        # Load model
        self.model = self._load_model()
        
        # Kh·ªüi t·∫°o detector v√† controller
        self.detector = HandLandmarksDetector()
        self.esp32_controller = ESP32Controller(esp32_ip)
        
        # Thi·∫øt l·∫≠p parameters
        self.confidence_threshold = 0.8
        self.gesture_threshold = 15  # S·ªë frame li√™n ti·∫øp ƒë·ªÉ x√°c nh·∫≠n c·ª≠ ch·ªâ
        self.cooldown_time = 2.0     # Th·ªùi gian ch·ªù gi·ªØa c√°c l·ªánh (gi√¢y)
        
        print(f"‚úÖ GestureController ƒë√£ s·∫µn s√†ng v·ªõi {self.num_classes} c·ª≠ ch·ªâ")
    
    def _load_gesture_config(self) -> Dict[int, str]:
        """ƒê·ªçc c·∫•u h√¨nh c·ª≠ ch·ªâ t·ª´ file YAML"""
        try:
            with open(self.config_path, 'r', encoding='utf-8') as file:
                config = yaml.safe_load(file)
                return config.get('gestures', {})
        except FileNotFoundError:
            print(f"‚ùå Kh√¥ng t√¨m th·∫•y file config: {self.config_path}")
            return {}
        except Exception as e:
            print(f"‚ùå L·ªói ƒë·ªçc config: {e}")
            return {}
    
    def _load_model(self) -> HandGestureModel:
        """Load model ƒë√£ ƒë∆∞·ª£c training t·ª´ Step 2"""
        try:
            checkpoint = torch.load(self.model_path, map_location='cpu')
            
            # L·∫•y th√¥ng tin t·ª´ checkpoint
            saved_labels = checkpoint.get('gesture_labels', {})
            saved_num_classes = checkpoint.get('num_classes', len(saved_labels))
            
            # Kh·ªüi t·∫°o model
            model = HandGestureModel(num_classes=saved_num_classes)
            model.load_state_dict(checkpoint['model_state_dict'])
            model.eval()
            
            print(f"‚úÖ ƒê√£ load model t·ª´: {self.model_path}")
            print(f"   Model classes: {saved_num_classes}")
            print(f"   Gesture labels: {saved_labels}")
            
            return model
            
        except FileNotFoundError:
            print(f"‚ùå Kh√¥ng t√¨m th·∫•y file model: {self.model_path}")
            raise
        except Exception as e:
            print(f"‚ùå L·ªói load model: {e}")
            raise
    
    def predict_gesture(self, landmarks: List[float]) -> Tuple[Optional[int], float]:
        """D·ª± ƒëo√°n c·ª≠ ch·ªâ t·ª´ landmarks"""
        if landmarks is None or len(landmarks) != 63:
            return None, 0.0
        
        try:
            # Chuy·ªÉn ƒë·ªïi th√†nh tensor
            landmarks_tensor = torch.tensor(landmarks, dtype=torch.float32).unsqueeze(0)
            
            with torch.no_grad():
                outputs = self.model(landmarks_tensor)
                probabilities = torch.softmax(outputs, dim=1)
                confidence, predicted = torch.max(probabilities, 1)
                
                return predicted.item(), confidence.item()
                
        except Exception as e:
            print(f"‚ùå L·ªói d·ª± ƒëo√°n: {e}")
            return None, 0.0
    
    def run_control(self, camera_index: int = 0, resolution: Tuple[int, int] = (1280, 720)):
        """
        Ch·∫°y v√≤ng l·∫∑p ch√≠nh ƒëi·ªÅu khi·ªÉn real-time
        
        Args:
            camera_index: Index c·ªßa camera (0, 1, 2...)
            resolution: ƒê·ªô ph√¢n gi·∫£i camera
        """
        # Kh·ªüi t·∫°o camera
        cap = cv2.VideoCapture(camera_index)
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, resolution[0])
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, resolution[1])
        
        if not cap.isOpened():
            print(f"‚ùå Kh√¥ng th·ªÉ m·ªü camera {camera_index}")
            return
        
        # Bi·∫øn theo d√µi tr·∫°ng th√°i
        last_gesture = None
        gesture_count = 0
        last_command_time = 0
        
        print("\n" + "="*60)
        print("    üéÆ GESTURE CONTROL STARTED")
        print("="*60)
        print("üìπ Camera ƒëang ch·∫°y...")
        print("ü§≤ Th·ª±c hi·ªán c·ª≠ ch·ªâ tr∆∞·ªõc camera ƒë·ªÉ ƒëi·ªÅu khi·ªÉn ESP32")
        print("‚å®Ô∏è Nh·∫•n 'q' ƒë·ªÉ tho√°t, 'r' ƒë·ªÉ reconnect ESP32")
        print("="*60)
        
        while True:
            ret, frame = cap.read()
            if not ret:
                print("‚ùå Kh√¥ng th·ªÉ ƒë·ªçc frame t·ª´ camera")
                break
            
            # Tr√≠ch xu·∫•t landmarks
            landmarks, hand_landmarks = self.detector.extract_landmarks(frame)
            
            # V·∫Ω landmarks n·∫øu c√≥
            if hand_landmarks:
                self.detector.draw_landmarks(frame, hand_landmarks)
            
            # D·ª± ƒëo√°n v√† ƒëi·ªÅu khi·ªÉn
            if landmarks:
                gesture_id, confidence = self.predict_gesture(landmarks)
                
                if gesture_id is not None and confidence > self.confidence_threshold:
                    gesture_name = self.gesture_labels.get(gesture_id, f"Unknown_{gesture_id}")
                    
                    # Ki·ªÉm tra t√≠nh nh·∫•t qu√°n c·ªßa c·ª≠ ch·ªâ
                    if gesture_id == last_gesture:
                        gesture_count += 1
                    else:
                        last_gesture = gesture_id
                        gesture_count = 1
                    
                    # G·ª≠i l·ªánh n·∫øu c·ª≠ ch·ªâ ·ªïn ƒë·ªãnh v√† ƒë√£ qua cooldown time
                    current_time = time.time()
                    if (gesture_count >= self.gesture_threshold and 
                        current_time - last_command_time > self.cooldown_time):
                        
                        success = self.esp32_controller.send_command(gesture_id, gesture_name)
                        if success:
                            last_command_time = current_time
                        
                        gesture_count = 0  # Reset ƒë·ªÉ tr√°nh g·ª≠i li√™n t·ª•c
                    
                    # Hi·ªÉn th·ªã th√¥ng tin tr√™n frame
                    info_text = f"{gesture_name} ({confidence:.2f})"
                    progress_text = f"Progress: {gesture_count}/{self.gesture_threshold}"
                    
                    cv2.putText(frame, info_text, (10, 30),
                               cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
                    cv2.putText(frame, progress_text, (10, 70),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)
                else:
                    last_gesture = None
                    gesture_count = 0
            else:
                last_gesture = None
                gesture_count = 0
            
            # Hi·ªÉn th·ªã tr·∫°ng th√°i ESP32
            esp32_status = "üü¢ Connected" if self.esp32_controller.is_connected else "üî¥ Disconnected"
            cv2.putText(frame, f"ESP32: {esp32_status}", (10, frame.shape[0] - 20),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)
            
            # Hi·ªÉn th·ªã frame
            cv2.imshow('Gesture Control - ESP32', frame)
            
            # X·ª≠ l√Ω ph√≠m nh·∫•n
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                print("\nüëã Tho√°t ch∆∞∆°ng tr√¨nh...")
                break
            elif key == ord('r'):
                print("\nüîÑ Reconnecting ESP32...")
                self.esp32_controller.reconnect()
        
        # Gi·∫£i ph√≥ng t√†i nguy√™n
        cap.release()
        cv2.destroyAllWindows()
        print("‚úÖ ƒê√£ d·ªçn d·∫πp t√†i nguy√™n")


def find_latest_model(models_dir: str = "../Step_2/models") -> Optional[str]:
    """T√¨m file model m·ªõi nh·∫•t trong th∆∞ m·ª•c models"""
    try:
        if not os.path.exists(models_dir):
            return None
        
        model_files = [f for f in os.listdir(models_dir) if f.endswith('.pth')]
        if not model_files:
            return None
        
        # S·∫Øp x·∫øp theo th·ªùi gian t·∫°o (m·ªõi nh·∫•t)
        model_files.sort(key=lambda x: os.path.getctime(os.path.join(models_dir, x)), reverse=True)
        latest_model = os.path.join(models_dir, model_files[0])
        
        return latest_model
        
    except Exception as e:
        print(f"‚ùå L·ªói t√¨m model: {e}")
        return None


def main():
    """H√†m main cho Step 3"""
    print("="*60)
    print("      STEP 3: GESTURE CONTROL")
    print("="*60)
    
    # T√¨m model t·ª± ƒë·ªông ho·∫∑c nh·∫≠p th·ªß c√¥ng
    latest_model = find_latest_model()
    
    if latest_model:
        print(f"üìÅ T√¨m th·∫•y model m·ªõi nh·∫•t: {os.path.basename(latest_model)}")
        use_latest = input("S·ª≠ d·ª•ng model n√†y? (y/n, m·∫∑c ƒë·ªãnh: y): ").lower()
        
        if use_latest in ['', 'y', 'yes']:
            model_path = latest_model
        else:
            model_path = input("Nh·∫≠p ƒë∆∞·ªùng d·∫´n ƒë·∫øn file model (.pth): ")
    else:
        print("‚ùå Kh√¥ng t√¨m th·∫•y model trong ../Step_2/models/")
        model_path = input("Nh·∫≠p ƒë∆∞·ªùng d·∫´n ƒë·∫øn file model (.pth): ")
    
    # Ki·ªÉm tra file model
    if not os.path.exists(model_path):
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y file model: {model_path}")
        return
    
    # Nh·∫≠p IP ESP32
    esp32_ip = input("üåê Nh·∫≠p IP c·ªßa ESP32 (m·∫∑c ƒë·ªãnh: 192.168.1.100): ") or "192.168.1.100"
    
    try:
        # Kh·ªüi t·∫°o controller
        controller = GestureController(model_path, esp32_ip)
        
        # Ch·∫°y ƒëi·ªÅu khi·ªÉn
        controller.run_control()
        
    except Exception as e:
        print(f"‚ùå L·ªói kh·ªüi t·∫°o: {e}")


if __name__ == "__main__":
    main()
